Geograph GridFS Implementation

	A new lightweight virtual distributed filesystem (DFS) to address 
	many of the problems faced with the current Network File System (NFS)
	used on the Live Geograph WebServers. 

	Basically, takes a number of storage servers, and presents a single 
	unified and clean file system. At the same time making sure files are 
	sent to remote backup locations for safe keeping. 

	/Barry Hunter (geo@barryhunter.co.uk) Aug 2013

1. Scripts included

	geogridfs.py
		This the FUSE client. It its run on all "Clients" that need to read/write to the virtual filesystem

	replicator.py
		This script is run on every "Storage Node", it iteracts with the metadata server and replicates new files to the local storage
	
	geograph_backup.py
		This script is run on every "Backup Node", it contacts a central API to find new files to download

	filesystem-api.php
		Central API endpoint, runs on webserver with access to metadata server, also authenticates and controls/throttles remote backup replication

	filesystem.php
		Optional PHP script that uses the metadata server to present some statistics and health of the whole system. Probably runs on same webserver as the API endpoint


2. Initial setup for all (can skip this for backup nodes)

	svn checkout http://svn.geograph.org.uk/svn/apps/trunk/geogridfs/ /folder/of/your/choice

	Copy config.example.py to config.py

	Edit config.py to point to a real database, correct mount list, and identity - see file for details

	If this is the first ever use, need to import database.sql into the database



3. Provisioning a Storage Node 

	Make sure metadata knows about this node, (add this server to the replicas SET column in the file table)

	Run this ONCE, when a new storage node is added:

		python replicator.py -a walk
		
		will walk the local folder, tell the metedata about any unknown files, and add self to replicas of existing files

	Setup command to run via cron, eg once a minute. Runs a lightweight SQL query to find new files that should be copied to this node
		
		sudo -u www-data crontab -e

		* * * * * * /bin/python replicator.py -a replicate


4. Provisioning a Client

	Make sure can communicate with ALL storage nodes. Use NFS to mount the each nodes storage on a local mount point (listed in the config file) 

	As the www-data user, run

		python geogridfs.py /mnt/combined

	which should mount the virtual file system on /mnt/combined. In theory doing a ls on that folder, should now list files from ALL storage nodes. 

		(it might prompt you to install fuse and or python-fuse, eg `apt-get install python-fuse`

	To unmount it run 	
		fusermount -u /mnt/combined


5. Provisioning a Backup Node (Linux!)

	Download the code and put it somewhere convenient (just one file needed!)

		http://svn.geograph.org.uk/svn/apps/trunk/geogridfs/geograph_backup.py

	Try running the file (this command wont do anything, other than check you have python and all the required modules installed!)

		python /path/to/geograph_backup.py 

		install any missing modules it complains about!

	Edit the config near the top of the file - Contact the Filesystem Admin for the values to enter in your client (if you are the admin, make sure the database knows about this new backup-node!)

	Set the 'folder' to where you want put files. Note this folder will contain folder "geograph_live", which in turn contains "public_html", but we may from time to time create other folders

		So if you want images to be stored in 

			/var/backups/geograph/geograph_live/public_html
		
		folder, set folder = '/var/backups/geograph'

	If the folder is empty, then just setup a cronjob to execute, it say once an hour (exact schedule, by agreement of Geograph admin!) 

		33 * * * * * python /path/to/geograph_backup.py -a replicate


	But if you have files in the folder, first need to 'walk' it to notify the central server of the files you have alrady got a copy of. 

		Quickly test it by running

			python /path/to/geograph_backup.py -a walk -p /geograph_live/public_html/photo/00/00

		which will only compare about 100 files. Will for example replicate the file

			/var/backups/geograph/geograph_live/public_html/photos/00/00/000004_a2a3a15c.jpg

		Once run the test successfully, can run it on more folders eg, 

			python /path/to/geograph_backup.py -a walk -p /geograph_live/public_html/photo

		... it make take MANY hours to run. Your computer will work hard, as it has to read each file (to create a checksum), but is lightweight for the server, as it already has checksums precomputed

	Once the WHOLE of your local filesystem has been 'walk'ed ready to run regular replicate, setup a cronjob as above to call the replicate action. 

6. Provisioning a Backup Node (Windows!)

	Coming soon... 

